{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b476ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import metrics\n",
    "from read_tfrecord import *\n",
    "from mtcnn_model import Rnet,cls_ohem,cal_accuracy,bbox_ohem\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5400531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/24/train_RNet_landmark.tfrecord_shuffle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c4f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pokemon(mode='train'):\n",
    "    \"\"\" 加载pokemon数据集的工具！\n",
    "    :param root:    数据集存储的目录\n",
    "    :param mode:    mode:当前加载的数据是train,val,还是test\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # # 创建数字编码表,范围0-4;\n",
    "    # name2label = {}  # \"sq...\":0   类别名:类标签;  字典 可以看一下目录,一共有5个文件夹,5个类别：0-4范围;\n",
    "    # for name in sorted(os.listdir(os.path.join(root))):     # 列出所有目录;\n",
    "    #     if not os.path.isdir(os.path.join(root, name)):\n",
    "    #         continue\n",
    "    #     # 给每个类别编码一个数字\n",
    "    #     name2label[name] = len(name2label.keys())\n",
    " \n",
    "    # 读取Label信息;保存索引文件images.csv\n",
    "    # [file1,file2,], 对应的标签[3,1] 2个一一对应的list对象。\n",
    "    # 根据目录,把每个照片的路径提取出来,以及每个照片路径所对应的类别都存储起来，存储到CSV文件中。\n",
    "    size = 24\n",
    "    images,labels,boxes = red_tf(data_path,size)\n",
    " \n",
    "    # 图片切割成，训练70%，验证15%，测试15%。\n",
    "    if mode == 'train':                                                     # 100% 训练集\n",
    "        images = images[:int(len(images))]\n",
    "        labels = labels[:int(len(labels))]\n",
    "        boxes  = boxes[:int(len(boxes))]\n",
    "    elif mode == 'val':                                                     # 15% = 70%->85%  验证集\n",
    "        images = images[int(0.7 * len(images)):int(0.85 * len(images))]\n",
    "        labels = labels[int(0.7 * len(labels)):int(0.85 * len(labels))]\n",
    "        boxes = boxes[int(0.7 * len(boxes)):int(0.85 * len(boxes))]\n",
    "    else:                                                                   # 15% = 70%->85%  测试集\n",
    "        images = images[int(0.85 * len(images)):]\n",
    "        labels = labels[int(0.85 * len(labels)):]\n",
    "        boxes = boxes[int(0.85 * len(boxes)):]\n",
    "    ima = tf.data.Dataset.from_tensor_slices(images)\n",
    "    lab = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    roi = tf.data.Dataset.from_tensor_slices(boxes)\n",
    " \n",
    "    train_data = tf.data.Dataset.zip((ima, lab, roi)).shuffle(1000).batch(16)\n",
    "    train_data = list(train_data.as_numpy_iterator())\n",
    "    return train_data\n",
    "\n",
    "# 图像色相变换\n",
    "def image_color_distort(inputs):\n",
    "    inputs = tf.image.random_contrast(inputs, lower=0.5, upper=1.5)\n",
    "    inputs = tf.image.random_brightness(inputs, max_delta=0.2)\n",
    "    inputs = tf.image.random_hue(inputs,max_delta= 0.2)\n",
    "    inputs = tf.image.random_saturation(inputs,lower = 0.5, upper= 1.5)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0355f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model = Rnet()\n",
    "    #model.load_weights(\"rnet.h5\")\n",
    " \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    off = 1000\n",
    "    acc_meter = metrics.Accuracy()\n",
    "    for epoch in tqdm(range(eopch)):\n",
    " \n",
    "        for i,(img,lab,boxes) in enumerate(load_pokemon(\"train\")):\n",
    " \n",
    " \n",
    "            img = image_color_distort(img)\n",
    "            # 开一个gradient tape, 计算梯度\n",
    "            with tf.GradientTape() as tape:\n",
    "                cls_prob, bbox_pred = model(img)\n",
    "                cls_loss = cls_ohem(cls_prob, lab)\n",
    "                bbox_loss = bbox_ohem(bbox_pred, boxes,lab)\n",
    "                # landmark_loss = landmark_loss_fn(landmark_pred, landmark_batch, label_batch)\n",
    "                # accuracy = cal_accuracy(cls_prob, label_batch)\n",
    " \n",
    " \n",
    "                total_loss_value = cls_loss + 0.5 * bbox_loss\n",
    "                grads = tape.gradient(total_loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if i % 200 == 0:\n",
    "                print('Training loss (for one batch) at step %s: %s' % (i, float(total_loss_value)))\n",
    "                print('Seen so far: %s samples' % ((i + 1) * 16))\n",
    " \n",
    " \n",
    "        for i, (v_img, v_lab1, boxes) in enumerate(load_pokemon(\"val\")):\n",
    "            v_img = image_color_distort(v_img)\n",
    "            with tf.GradientTape() as tape:\n",
    "                cls_prob, bbox_pred = model(v_img)\n",
    "                cls_loss = cls_ohem(cls_prob, v_lab1)\n",
    "                bbox_loss = bbox_ohem(bbox_pred, boxes,v_lab1)\n",
    "                # landmark_loss = landmark_loss_fn(landmark_pred, landmark_batch, label_batch)\n",
    "                # accuracy = cal_accuracy(cls_prob, label_batch)\n",
    " \n",
    " \n",
    "                total_loss_value = cls_loss + 0.5 * bbox_loss\n",
    "                grads = tape.gradient(total_loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if i % 200 == 0:\n",
    "                print('val___ loss (for one batch) at step %s: %s' % (i, float(total_loss_value)))\n",
    "                print('Seen so far: %s samples' % ((i + 1) * 16))\n",
    "    model.save_weights('./Weights/Rnet_wight/rnet_30.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2faf5f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.7099941968917847\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.759408175945282\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.36534103751182556\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.48153743147850037\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [00:30<14:39, 30.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.379951536655426\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.6552779078483582\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.45284023880958557\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.5992808938026428\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [01:01<14:19, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.6919435262680054\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.5512128472328186\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.39910224080085754\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.1444886475801468\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [01:33<14:06, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.17537197470664978\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.28509843349456787\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.09588472545146942\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.15612077713012695\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [02:07<14:01, 32.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.5717464089393616\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.2672243118286133\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.5149610638618469\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.18985050916671753\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [02:38<13:14, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.5195857882499695\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.026812013238668442\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.06818695366382599\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.09511698782444\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [03:07<12:26, 31.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.18292884528636932\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.3623223900794983\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.06994132697582245\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.17413915693759918\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [03:39<11:56, 31.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.3124150037765503\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.296311616897583\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.2578215003013611\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.34535083174705505\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [04:11<11:35, 31.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.5196733474731445\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.06939063221216202\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.08763343095779419\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.06074310094118118\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [04:44<11:12, 32.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.2866215705871582\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.1178138479590416\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.017446380108594894\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.5025572776794434\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [05:16<10:38, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.1954815834760666\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.2605285346508026\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.06579816341400146\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.23375225067138672\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [05:46<09:58, 31.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.039395540952682495\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.11905145645141602\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.13889795541763306\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.11852061748504639\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [06:18<09:26, 31.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.05867672339081764\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.1605895757675171\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 1.070317029953003\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.062456388026475906\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [06:52<09:07, 32.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.2789013385772705\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.02398005872964859\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.07661443203687668\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.08240294456481934\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [07:24<08:37, 32.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.1409839689731598\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.1447594314813614\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.12926052510738373\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.018986446782946587\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [07:55<07:58, 31.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.09975941479206085\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.03878071904182434\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.06349728256464005\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.016655337065458298\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [08:25<07:19, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.1828557550907135\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.050751157104969025\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.10142441093921661\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.014408448711037636\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [08:56<06:43, 31.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.2534688115119934\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.04439892619848251\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.04727093130350113\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.041744474321603775\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [09:26<06:09, 30.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.1680421531200409\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.020053662359714508\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.26532578468322754\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.13998576998710632\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [09:57<05:38, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.013579932041466236\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.04342120140790939\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.09957018494606018\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.017495786771178246\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [10:28<05:08, 30.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.049668945372104645\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.28714099526405334\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: nan\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.04454731568694115\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [11:00<04:41, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.13252224028110504\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.12319239228963852\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: nan\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.0588918998837471\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [11:31<04:10, 31.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.08538715541362762\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.22153253853321075\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.02536754682660103\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.09171731024980545\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [12:01<03:36, 30.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.18997430801391602\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.04130502790212631\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.047594279050827026\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.042580392211675644\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [12:31<03:03, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.032683201134204865\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.19677871465682983\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.008276919834315777\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.03637594357132912\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [13:02<02:32, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.08375795185565948\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.046845365315675735\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.03595973923802376\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.026146240532398224\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [13:32<02:01, 30.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.04100316762924194\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.015040452592074871\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.053399618715047836\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.024672595784068108\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [14:02<01:31, 30.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.04294443875551224\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.023213252425193787\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.06706096231937408\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.06720176339149475\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [14:33<01:00, 30.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.07273033261299133\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.12310439348220825\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.014622936956584454\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.017498411238193512\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [15:03<00:30, 30.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.11741043627262115\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.07665160298347473\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.028185630217194557\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.004512411076575518\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [15:34<00:00, 31.15s/it]\n"
     ]
    }
   ],
   "source": [
    "train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc4a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
