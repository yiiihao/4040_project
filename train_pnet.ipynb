{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90dd56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import metrics\n",
    "from read_tfrecord import *\n",
    "from mtcnn_model import Pnet,cls_ohem,bbox_ohem\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ca63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/12/train_PNet_landmark.tfrecord_shuffle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b1aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pokemon(mode='train'):\n",
    "    \"\"\" 加载pokemon数据集的工具！\n",
    "    :param root:    数据集存储的目录\n",
    "    :param mode:    mode:当前加载的数据是train,val,还是test\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # # 创建数字编码表,范围0-4;\n",
    "    # name2label = {}  # \"sq...\":0   类别名:类标签;  字典 可以看一下目录,一共有5个文件夹,5个类别：0-4范围;\n",
    "    # for name in sorted(os.listdir(os.path.join(root))):     # 列出所有目录;\n",
    "    #     if not os.path.isdir(os.path.join(root, name)):\n",
    "    #         continue\n",
    "    #     # 给每个类别编码一个数字\n",
    "    #     name2label[name] = len(name2label.keys())\n",
    " \n",
    "    # 读取Label信息;保存索引文件images.csv\n",
    "    # [file1,file2,], 对应的标签[3,1] 2个一一对应的list对象。\n",
    "    # 根据目录,把每个照片的路径提取出来,以及每个照片路径所对应的类别都存储起来，存储到CSV文件中。\n",
    "    size = 12\n",
    "    images,labels,boxes = red_tf(data_path,size)\n",
    " \n",
    "    # 图片切割成，训练70%，验证15%，测试15%。\n",
    "    if mode == 'train':                                                     # 70% 训练集\n",
    "        images = images[:int(0.7 * len(images))]\n",
    "        labels = labels[:int(0.7 * len(labels))]\n",
    "        boxes  = boxes[:int(0.7 * len(boxes))]\n",
    "    elif mode == 'val':                                                     # 15% = 70%->85%  验证集\n",
    "        images = images[int(0.7 * len(images)):int(0.85 * len(images))]\n",
    "        labels = labels[int(0.7 * len(labels)):int(0.85 * len(labels))]\n",
    "        boxes = boxes[int(0.7 * len(boxes)):int(0.85 * len(boxes))]\n",
    "    else:                                                                   # 15% = 70%->85%  测试集\n",
    "        images = images[int(0.85 * len(images)):]\n",
    "        labels = labels[int(0.85 * len(labels)):]\n",
    "        boxes = boxes[int(0.85 * len(boxes)):]\n",
    "    ima = tf.data.Dataset.from_tensor_slices(images)\n",
    "    lab = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    roi = tf.data.Dataset.from_tensor_slices(boxes)\n",
    "    # ima,lab,roi = preprocess(ima,lab,roi)\n",
    "    train_data = tf.data.Dataset.zip((ima, lab, roi)).shuffle(1000).batch(32)\n",
    "    train_data = list(train_data.as_numpy_iterator())\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf83bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "0\n",
      "[[[[ 9.00470257e-01  7.88879871e-01  7.78909564e-01]\n",
      "   [ 1.74341947e-02  1.65860786e-03  0.00000000e+00]\n",
      "   [ 4.45009530e-01  4.01061982e-01  3.81063819e-01]\n",
      "   ...\n",
      "   [ 7.14567900e-01  5.37726879e-01  4.43208456e-01]\n",
      "   [ 5.84436297e-01  4.58168507e-01  4.82645035e-01]\n",
      "   [-1.12697437e-01 -1.12697437e-01 -1.12697437e-01]]\n",
      "\n",
      "  [[ 7.14567900e-01  5.81127524e-01  5.46915293e-01]\n",
      "   [ 3.60244215e-02  1.31991673e-02  0.00000000e+00]\n",
      "   [ 6.58797264e-01  6.03625715e-01  5.83328485e-01]\n",
      "   ...\n",
      "   [ 2.40516990e-01  8.37754756e-02  0.00000000e+00]\n",
      "   [ 2.12631613e-01  8.63638222e-02  9.93174016e-02]\n",
      "   [ 2.86992580e-01  2.06816673e-01  2.55535245e-01]]\n",
      "\n",
      "  [[ 2.67293081e-02  1.01918224e-02  0.00000000e+00]\n",
      "   [ 8.44699502e-01  7.45529115e-01  6.88569903e-01]\n",
      "   [ 7.51748323e-01  6.62605941e-01  6.53233707e-01]\n",
      "   ...\n",
      "   [ 6.39097691e-02  2.47470960e-02  0.00000000e+00]\n",
      "   [ 1.94041401e-01  6.06011003e-02  2.63888091e-02]\n",
      "   [ 9.37650681e-01  8.45951796e-01  8.48279536e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 3.02486271e-01  3.15269172e-01  2.85407364e-01]\n",
      "   [-2.57230937e-01 -2.57230937e-01 -2.57230937e-01]\n",
      "   [-1.45689577e-01 -1.45689577e-01 -1.45689577e-01]\n",
      "   ...\n",
      "   [-1.00599155e-02 -1.00599155e-02 -1.00599155e-02]\n",
      "   [ 5.77132463e-01  6.33004606e-01  6.62985563e-01]\n",
      "   [ 6.63400054e-01  7.29897976e-01  7.83822060e-01]]\n",
      "\n",
      "  [[ 4.53195423e-02  2.87390575e-02  0.00000000e+00]\n",
      "   [ 7.05002129e-01  7.05664039e-01  6.98848188e-01]\n",
      "   [ 1.08304545e-01  1.62382543e-01  2.63295531e-01]\n",
      "   ...\n",
      "   [ 1.84746280e-01  1.63246661e-01  1.43846527e-01]\n",
      "   [ 2.91738182e-01  3.15269172e-01  3.09063971e-01]\n",
      "   [ 7.69718409e-01  8.14964533e-01  8.21002483e-01]]\n",
      "\n",
      "  [[-3.54370445e-01 -3.54370445e-01 -3.54370445e-01]\n",
      "   [ 4.26419318e-01  4.04919714e-01  3.85519564e-01]\n",
      "   [ 9.19207513e-01  9.85107481e-01  1.06267548e+00]\n",
      "   ...\n",
      "   [-1.21992558e-01 -1.21992558e-01 -1.21992558e-01]\n",
      "   [-1.95962220e-01 -1.95962220e-01 -1.95962220e-01]\n",
      "   [ 5.33411086e-01  5.56942225e-01  5.50737023e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.71638742e-01 -1.71638742e-01 -1.71638742e-01]\n",
      "   [-2.17900008e-01 -2.17900008e-01 -2.17900008e-01]\n",
      "   [-1.94336101e-01 -1.94336101e-01 -1.94336101e-01]\n",
      "   ...\n",
      "   [-2.71438211e-01 -2.71438211e-01 -2.71438211e-01]\n",
      "   [-4.30782616e-01 -4.30782616e-01 -4.30782616e-01]\n",
      "   [-5.54146051e-01 -5.54146051e-01 -5.54146051e-01]]\n",
      "\n",
      "  [[-2.38460571e-01 -2.38460571e-01 -2.38460571e-01]\n",
      "   [-2.95002133e-01 -2.95002133e-01 -2.95002133e-01]\n",
      "   [-2.95002133e-01 -2.95002133e-01 -2.95002133e-01]\n",
      "   ...\n",
      "   [-3.05282414e-01 -3.05282414e-01 -3.05282414e-01]\n",
      "   [-5.18164992e-01 -5.18164992e-01 -5.18164992e-01]\n",
      "   [-5.49005866e-01 -5.49005866e-01 -5.49005866e-01]]\n",
      "\n",
      "  [[-4.18365538e-01 -4.18365538e-01 -4.18365538e-01]\n",
      "   [-4.02945131e-01 -4.02945131e-01 -4.02945131e-01]\n",
      "   [-3.87524694e-01 -3.87524694e-01 -3.87524694e-01]\n",
      "   ...\n",
      "   [-1.04816899e-01 -1.04816899e-01 -1.04816899e-01]\n",
      "   [-4.85187382e-01 -4.85187382e-01 -4.85187382e-01]\n",
      "   [-5.00607848e-01 -5.00607848e-01 -5.00607848e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-2.02479601e-01 -2.02479601e-01 -2.02479601e-01]\n",
      "   [ 1.78183094e-01  1.82475194e-01  3.42375457e-01]\n",
      "   [ 0.00000000e+00  3.96160685e-05  2.36866474e-02]\n",
      "   ...\n",
      "   [-4.46203053e-01 -4.46203053e-01 -4.46203053e-01]\n",
      "   [-5.28445363e-01 -5.28445363e-01 -5.28445363e-01]\n",
      "   [-4.71903771e-01 -4.71903771e-01 -4.71903771e-01]]\n",
      "\n",
      "  [[-5.46869040e-01 -5.46869040e-01 -5.46869040e-01]\n",
      "   [-3.61823976e-01 -3.61823976e-01 -3.61823976e-01]\n",
      "   [ 2.11700681e-03  0.00000000e+00  1.85465217e-02]\n",
      "   ...\n",
      "   [-3.17699522e-01 -3.17699522e-01 -3.17699522e-01]\n",
      "   [-3.53680491e-01 -3.53680491e-01 -3.53680491e-01]\n",
      "   [-4.41062897e-01 -4.41062897e-01 -4.41062897e-01]]\n",
      "\n",
      "  [[-5.41728973e-01 -5.41728973e-01 -5.41728973e-01]\n",
      "   [-5.67429662e-01 -5.67429662e-01 -5.67429662e-01]\n",
      "   [-5.05747914e-01 -5.05747914e-01 -5.05747914e-01]\n",
      "   ...\n",
      "   [-2.76578367e-01 -2.76578367e-01 -2.76578367e-01]\n",
      "   [-5.43865800e-01 -5.43865800e-01 -5.43865800e-01]\n",
      "   [-3.48540366e-01 -3.48540366e-01 -3.48540366e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.57853264e-01  2.08003655e-01  3.05085957e-01]\n",
      "   [-7.35304877e-02 -7.35304877e-02 -7.35304877e-02]\n",
      "   [-6.92593604e-02 -6.92593604e-02 -6.92593604e-02]\n",
      "   ...\n",
      "   [-6.49882406e-02 -6.49882406e-02 -6.49882406e-02]\n",
      "   [-5.64459860e-02 -5.64459860e-02 -5.64459860e-02]\n",
      "   [-6.07171059e-02 -6.07171059e-02 -6.07171059e-02]]\n",
      "\n",
      "  [[ 4.00564551e-01  2.41797239e-01  3.55876803e-01]\n",
      "   [-6.07171059e-02 -6.07171059e-02 -6.07171059e-02]\n",
      "   [ 2.42532849e-01  9.93714929e-02  2.08229512e-01]\n",
      "   ...\n",
      "   [-8.63438696e-02 -8.63438696e-02 -8.63438696e-02]\n",
      "   [-1.41868502e-01 -1.41868502e-01 -1.41868502e-01]\n",
      "   [-1.63224131e-01 -1.63224131e-01 -1.63224131e-01]]\n",
      "\n",
      "  [[ 4.26191270e-01  2.58506298e-01  3.98500741e-01]\n",
      "   [-6.92593604e-02 -6.92593604e-02 -6.92593604e-02]\n",
      "   [ 4.09106791e-01  2.52568901e-01  3.69087487e-01]\n",
      "   ...\n",
      "   [-1.71766400e-01 -1.71766400e-01 -1.71766400e-01]\n",
      "   [-2.27291018e-01 -2.27291018e-01 -2.27291018e-01]\n",
      "   [ 0.00000000e+00  2.40110680e-02  3.23311687e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 4.77596819e-02  2.50158638e-01  1.90846041e-01]\n",
      "   [ 2.90089101e-02  2.20260769e-01  1.62129983e-01]\n",
      "   [ 3.62603068e-02  2.07447380e-01  1.49660259e-01]\n",
      "   ...\n",
      "   [-7.01758564e-02 -7.01758564e-02 -7.01758564e-02]\n",
      "   [-6.92593604e-02 -6.92593604e-02 -6.92593604e-02]\n",
      "   [ 3.74937773e-01  2.71906018e-01  3.62241387e-01]]\n",
      "\n",
      "  [[ 7.47004449e-02  2.45887518e-01  1.88100398e-01]\n",
      "   [ 6.05962276e-02  2.11718500e-01  1.60963252e-01]\n",
      "   [ 4.13054675e-02  1.43380463e-01  1.19227462e-01]\n",
      "   ...\n",
      "   [ 0.00000000e+00  1.56552047e-02  2.37889141e-02]\n",
      "   [ 2.88820148e-01  2.34084889e-01  2.89515227e-01]\n",
      "   [-1.07699491e-01 -1.07699491e-01 -1.07699491e-01]]\n",
      "\n",
      "  [[ 1.99126273e-01  3.56936812e-01  2.97892481e-01]\n",
      "   [ 7.43481964e-02  2.03176260e-01  1.61472842e-01]\n",
      "   [ 1.79483250e-01  2.45887518e-01  2.38446757e-01]\n",
      "   ...\n",
      "   [-9.58026126e-02 -9.58026126e-02 -9.58026126e-02]\n",
      "   [ 2.72430718e-01  2.30376914e-01  2.72153586e-01]\n",
      "   [-1.84579760e-01 -1.84579760e-01 -1.84579760e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-9.56801414e-01 -9.56801414e-01 -9.56801414e-01]\n",
      "   [-8.67679596e-01 -8.67679596e-01 -8.67679596e-01]\n",
      "   [-8.37972343e-01 -8.37972343e-01 -8.37972343e-01]\n",
      "   ...\n",
      "   [-6.37448251e-01 -6.37448251e-01 -6.37448251e-01]\n",
      "   [-6.96862817e-01 -6.96862817e-01 -6.96862817e-01]\n",
      "   [-7.63704181e-01 -7.63704181e-01 -7.63704181e-01]]\n",
      "\n",
      "  [[-8.60252798e-01 -8.60252798e-01 -8.60252798e-01]\n",
      "   [-8.00838232e-01 -8.00838232e-01 -8.00838232e-01]\n",
      "   [-8.67679596e-01 -8.67679596e-01 -8.67679596e-01]\n",
      "   ...\n",
      "   [-2.88387805e-01 -2.88387805e-01 -2.88387805e-01]\n",
      "   [-3.84936452e-01 -3.84936452e-01 -3.84936452e-01]\n",
      "   [-5.85460544e-01 -5.85460544e-01 -5.85460544e-01]]\n",
      "\n",
      "  [[-8.00838232e-01 -8.00838232e-01 -8.00838232e-01]\n",
      "   [-7.71130979e-01 -7.71130979e-01 -7.71130979e-01]\n",
      "   [-8.75106454e-01 -8.75106454e-01 -8.75106454e-01]\n",
      "   ...\n",
      "   [-7.30100870e-02 -7.30100870e-02 -7.30100870e-02]\n",
      "   [-1.47278279e-01 -1.47278279e-01 -1.47278279e-01]\n",
      "   [-3.84936452e-01 -3.84936452e-01 -3.84936452e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-8.60252798e-01 -8.60252798e-01 -8.60252798e-01]\n",
      "   [-8.89960051e-01 -8.89960051e-01 -8.89960051e-01]\n",
      "   [-9.86508727e-01 -9.86508727e-01 -9.86508727e-01]\n",
      "   ...\n",
      "   [-4.88911897e-01 -4.88911897e-01 -4.88911897e-01]\n",
      "   [-5.26045978e-01 -5.26045978e-01 -5.26045978e-01]\n",
      "   [-5.33472776e-01 -5.33472776e-01 -5.33472776e-01]]\n",
      "\n",
      "  [[-9.27094162e-01 -9.27094162e-01 -9.27094162e-01]\n",
      "   [-9.56801414e-01 -9.56801414e-01 -9.56801414e-01]\n",
      "   [-1.00136232e+00 -1.00136232e+00 -1.00136232e+00]\n",
      "   ...\n",
      "   [-3.92363250e-01 -3.92363250e-01 -3.92363250e-01]\n",
      "   [-5.03765523e-01 -5.03765523e-01 -5.03765523e-01]\n",
      "   [-6.74582362e-01 -6.74582362e-01 -6.74582362e-01]]\n",
      "\n",
      "  [[-1.01621604e+00 -1.01621604e+00 -1.01621604e+00]\n",
      "   [-1.00136232e+00 -1.00136232e+00 -1.00136232e+00]\n",
      "   [-9.79081869e-01 -9.79081869e-01 -9.79081869e-01]\n",
      "   ...\n",
      "   [-3.25521916e-01 -3.25521916e-01 -3.25521916e-01]\n",
      "   [-4.96338725e-01 -4.96338725e-01 -4.96338725e-01]\n",
      "   [-8.15691888e-01 -8.15691888e-01 -8.15691888e-01]]]\n",
      "\n",
      "\n",
      " [[[-5.32012761e-01 -5.32012761e-01 -5.32012761e-01]\n",
      "   [-3.60595644e-01 -3.60595644e-01 -3.60595644e-01]\n",
      "   [-3.20461839e-02 -3.20461839e-02 -3.20461839e-02]\n",
      "   ...\n",
      "   [-5.96294224e-01 -5.96294224e-01 -5.96294224e-01]\n",
      "   [ 0.00000000e+00  3.15585881e-01  3.60784709e-01]\n",
      "   [-5.53439915e-01 -5.53439915e-01 -5.53439915e-01]]\n",
      "\n",
      "  [[ 0.00000000e+00  6.51073754e-02  1.17943808e-01]\n",
      "   [ 0.00000000e+00  2.16280580e-01  3.46499920e-01]\n",
      "   [ 0.00000000e+00  3.38856727e-02  4.65200096e-02]\n",
      "   ...\n",
      "   [ 7.35650957e-02  3.91303927e-01  5.17917037e-01]\n",
      "   [-8.91852304e-02 -8.91852304e-02 -8.91852304e-02]\n",
      "   [-5.17728031e-01 -5.17728031e-01 -5.17728031e-01]]\n",
      "\n",
      "  [[ 2.00130224e-01  4.93531495e-01  6.53622270e-01]\n",
      "   [ 1.83546811e-01  4.49310899e-01  5.82198441e-01]\n",
      "   [ 2.68653482e-01  5.09537458e-01  5.39344192e-01]\n",
      "   ...\n",
      "   [-2.60602325e-01 -2.60602325e-01 -2.60602325e-01]\n",
      "   [ 0.00000000e+00  2.21550334e-02  3.22352499e-02]\n",
      "   [-7.17714667e-01 -7.17714667e-01 -7.17714667e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 6.63508475e-01  6.19747579e-01  6.05156839e-01]\n",
      "   [ 6.56366050e-01  6.40133977e-01  6.25434637e-01]\n",
      "   [ 5.90005994e-01  6.25857115e-01  6.32195115e-01]\n",
      "   ...\n",
      "   [-6.74860418e-01 -6.74860418e-01 -6.74860418e-01]\n",
      "   [-9.46270823e-01 -9.46270823e-01 -9.46270823e-01]\n",
      "   [-1.03912175e+00 -1.03912175e+00 -1.03912175e+00]]\n",
      "\n",
      "  [[ 5.95076561e-01  6.01837695e-01  5.03584921e-01]\n",
      "   [ 7.05142140e-01  7.30400622e-01  6.86988115e-01]\n",
      "   [ 6.76863968e-01  7.03683496e-01  7.46473193e-01]\n",
      "   ...\n",
      "   [-8.03423226e-01 -8.03423226e-01 -8.03423226e-01]\n",
      "   [-8.96274149e-01 -8.96274149e-01 -8.96274149e-01]\n",
      "   [-8.57818484e-01 -8.57818484e-01 -8.57818484e-01]]\n",
      "\n",
      "  [[ 6.73923969e-01  7.01831043e-01  5.57877958e-01]\n",
      "   [ 6.69538736e-01  6.94688618e-01  6.23856068e-01]\n",
      "   [ 6.84006333e-01  7.29106128e-01  7.53615558e-01]\n",
      "   ...\n",
      "   [-7.93537021e-01 -7.93537021e-01 -7.93537021e-01]\n",
      "   [-9.50669408e-01 -9.50669408e-01 -9.50669408e-01]\n",
      "   [-5.86408019e-01 -5.86408019e-01 -5.86408019e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.20840657e-01 -3.20840657e-01 -3.20840657e-01]\n",
      "   [-1.54254019e-01 -1.54254019e-01 -1.54254019e-01]\n",
      "   [ 1.83545753e-01  1.76617444e-01  4.43943560e-01]\n",
      "   ...\n",
      "   [-4.26850379e-01 -4.26850379e-01 -4.26850379e-01]\n",
      "   [-4.26850379e-01 -4.26850379e-01 -4.26850379e-01]\n",
      "   [-3.28412831e-01 -3.28412831e-01 -3.28412831e-01]]\n",
      "\n",
      "  [[ 2.09072068e-01  2.04559684e-01  5.04520535e-01]\n",
      "   [ 1.03062406e-01  9.85500216e-02  3.98510814e-01]\n",
      "   [ 1.39224708e-01  1.37583703e-01  4.21227157e-01]\n",
      "   ...\n",
      "   [-1.79558434e-02 -1.79558434e-02 -1.79558434e-02]\n",
      "   [ 4.58356917e-01  4.53319728e-01  6.63535058e-01]\n",
      "   [-3.43557060e-01 -3.43557060e-01 -3.43557060e-01]]\n",
      "\n",
      "  [[ 2.91319281e-01  3.01232964e-01  6.48390830e-01]\n",
      "   [ 1.11507177e-02  2.10643988e-02  3.68222356e-01]\n",
      "   [ 2.63959426e-03  0.00000000e+00  2.54640520e-01]\n",
      "   ...\n",
      "   [ 1.82429235e-02  0.00000000e+00  2.16779903e-01]\n",
      "   [ 2.75523037e-01  2.73881882e-01  5.57525337e-01]\n",
      "   [ 0.00000000e+00  2.45364592e-03  7.29096085e-02]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-6.15522385e-01 -6.15522385e-01 -6.15522385e-01]\n",
      "   [-6.53383017e-01 -6.53383017e-01 -6.53383017e-01]\n",
      "   [-4.26219404e-01 -4.26219404e-01 -4.26219404e-01]\n",
      "   ...\n",
      "   [ 9.65856537e-02  1.70205981e-02  1.87122419e-01]\n",
      "   [-4.76133339e-02 -4.76133339e-02 -4.76133339e-02]\n",
      "   [-6.27575815e-02 -6.27575815e-02 -6.27575815e-02]]\n",
      "\n",
      "  [[-3.95930886e-01 -3.95930886e-01 -3.95930886e-01]\n",
      "   [-4.33791518e-01 -4.33791518e-01 -4.33791518e-01]\n",
      "   [ 1.20386839e-01  0.00000000e+00  1.49261817e-01]\n",
      "   ...\n",
      "   [-6.00378156e-01 -6.00378156e-01 -6.00378156e-01]\n",
      "   [-5.51854558e-02 -5.51854558e-02 -5.51854558e-02]\n",
      "   [ 1.11401200e-01  0.00000000e+00  9.52311382e-02]]\n",
      "\n",
      "  [[-6.38238728e-01 -6.38238728e-01 -6.38238728e-01]\n",
      "   [-2.67204821e-01 -2.67204821e-01 -2.67204821e-01]\n",
      "   [ 1.61584213e-01  0.00000000e+00  1.71978176e-01]\n",
      "   ...\n",
      "   [-4.78082240e-01 -4.78082240e-01 -4.78082240e-01]\n",
      "   [-2.52060592e-01 -2.52060592e-01 -2.52060592e-01]\n",
      "   [-1.76339388e-01 -1.76339388e-01 -1.76339388e-01]]]]\n",
      "[[ 0.    0.    0.    0.  ]\n",
      " [-0.07 -0.24 -0.16 -0.02]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.03 -0.21 -0.16  0.07]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [-0.03  0.05 -0.19 -0.24]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.08 -0.28 -0.04 -0.07]\n",
      " [ 0.2   0.05 -0.23 -0.17]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.06 -0.17  0.25  0.49]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.05 -0.04  0.23  0.29]\n",
      " [-0.05  0.1   0.05  0.19]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.06  0.03 -0.2  -0.16]\n",
      " [ 0.02 -0.02 -0.11  0.19]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [-0.07 -0.3   0.   -0.13]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.26  0.11  0.06  0.04]\n",
      " [ 0.15  0.03  0.09  0.  ]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.14 -0.11  0.04  0.09]\n",
      " [ 0.22  0.11  0.07  0.05]\n",
      " [ 0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "for i,(img,lab,boxes) in enumerate(load_pokemon(\"train\")):\n",
    "    print(i)\n",
    "    print(img)\n",
    "    print(boxes)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ac96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(eopch):\n",
    "    model = Pnet()\n",
    "    if os.path.exists(\"pnet.h5\"):\n",
    "        model.load_weights(\"pnet.h5\")\n",
    "    else:\n",
    "        model.load_weights('./Weights/pnet_wight/pnet_30.ckpt')\n",
    " \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    off = 1000\n",
    "    acc_meter = metrics.Accuracy()\n",
    "    for epoch in tqdm(range(eopch)):\n",
    " \n",
    "        for i,(img,lab,boxes) in enumerate(load_pokemon(\"train\")):\n",
    " \n",
    " \n",
    "            #img = image_color_distort(img)\n",
    "            # 开一个gradient tape, 计算梯度\n",
    "            with tf.GradientTape() as tape:\n",
    "                cls_prob, bbox_pred = model(img)\n",
    "                cls_prob = tf.squeeze(cls_prob,[1,2])\n",
    "                bbox_pred = tf.squeeze(bbox_pred,[1,2])\n",
    " \n",
    "                cls_loss = cls_ohem(cls_prob, lab)\n",
    "                bbox_loss = bbox_ohem(bbox_pred, boxes,lab)\n",
    "                # landmark_loss = landmark_loss_fn(landmark_pred, landmark_batch, label_batch)\n",
    "                # accuracy = cal_accuracy(cls_prob, label_batch)\n",
    " \n",
    " \n",
    "                total_loss_value = cls_loss + 0.5 * bbox_loss\n",
    "                grads = tape.gradient(total_loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if i % 200 == 0:\n",
    "                print('Training loss (for one batch) at step %s: %s' % (i, float(total_loss_value)))\n",
    "                print('Seen so far: %s samples' % ((i + 1) * 6))\n",
    " \n",
    " \n",
    "        for i, (v_img, v_lab1, boxes) in enumerate(load_pokemon(\"val\")):\n",
    "            v_img = image_color_distort(v_img)\n",
    "            with tf.GradientTape() as tape:\n",
    "                cls_prob, bbox_pred = model(v_img)\n",
    "                cls_prob = tf.squeeze(cls_prob,[1,2])\n",
    "                bbox_pred = tf.squeeze(bbox_pred,[1,2])\n",
    " \n",
    "                cls_loss = cls_ohem(cls_prob, v_lab1)\n",
    "                bbox_loss = bbox_ohem(bbox_pred, boxes,v_lab1)\n",
    "                # landmark_loss = landmark_loss_fn(landmark_pred, landmark_batch, label_batch)\n",
    "                # accuracy = cal_accuracy(cls_prob, label_batch)\n",
    " \n",
    " \n",
    "                total_loss_value = cls_loss + 0.5 * bbox_loss\n",
    "                grads = tape.gradient(total_loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if i % 200 == 0:\n",
    "                print('val___ loss (for one batch) at step %s: %s' % (i, float(total_loss_value)))\n",
    "                print('Seen so far: %s samples' % ((i + 1) * 6))\n",
    "    model.save_weights('./Weights/pnet_wight/pnet_30.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a203e8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.8359413146972656\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.4155491590499878\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.27837345004081726\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.44817817211151123\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [00:54<26:26, 54.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.4671699106693268\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.40162765979766846\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.3424588441848755\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.4209800660610199\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [01:53<26:44, 57.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.23878124356269836\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.20901580154895782\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.3559603691101074\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.32617372274398804\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [02:54<26:28, 58.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.21128727495670319\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.26134833693504333\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.2097095102071762\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.5597795248031616\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [03:53<25:30, 58.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.32778674364089966\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.3099137544631958\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.8357489109039307\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.6226744651794434\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [04:49<24:10, 58.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.15539149940013885\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.3994723856449127\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.2079479992389679\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.28386083245277405\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [05:45<22:54, 57.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.13109105825424194\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.07819440960884094\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.25583767890930176\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.2956675887107849\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [06:38<21:21, 55.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.39475417137145996\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.20401710271835327\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.10113663971424103\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.5593470335006714\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [07:35<20:33, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.26225367188453674\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.16128742694854736\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.6717553734779358\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.22885854542255402\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [08:32<19:47, 56.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.4598860442638397\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.16377052664756775\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.1625930368900299\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.36728572845458984\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [09:30<18:56, 56.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.3414551019668579\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.3016895353794098\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.30138951539993286\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.19241511821746826\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [10:26<17:59, 56.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.26393577456474304\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.43968844413757324\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.5612716674804688\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.2735404372215271\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [11:21<16:52, 56.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.14471586048603058\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.22394926846027374\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.48972246050834656\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.25902625918388367\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 13/30 [12:14<15:39, 55.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.1740548312664032\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.14161084592342377\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.21832971274852753\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.31117185950279236\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 14/30 [13:08<14:35, 54.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.370607852935791\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.0887947827577591\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.27876147627830505\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.2512228488922119\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 15/30 [14:02<13:39, 54.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.189750537276268\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.17744845151901245\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.2021373063325882\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.08501515537500381\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 16/30 [14:56<12:43, 54.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.31078431010246277\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.13701222836971283\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.16774658858776093\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.24951130151748657\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 17/30 [15:52<11:50, 54.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.231546550989151\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.18861792981624603\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.2362194061279297\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.20827516913414001\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 18/30 [16:52<11:18, 56.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.07180434465408325\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.16531826555728912\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.19397851824760437\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.11226218938827515\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 19/30 [17:49<10:21, 56.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.16892172396183014\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.14401447772979736\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.19230926036834717\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.18077287077903748\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 20/30 [18:45<09:24, 56.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.11585810780525208\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.11359743028879166\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.11347741633653641\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.12124735116958618\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 21/30 [19:45<08:36, 57.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.11416196078062057\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.1410733163356781\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.11333727091550827\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.15540054440498352\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 22/30 [20:47<07:49, 58.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.13033220171928406\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.0984228178858757\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.22125379741191864\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.4421785771846771\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 23/30 [21:44<06:49, 58.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.07140830159187317\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.13714268803596497\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.05262817069888115\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.30336976051330566\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 24/30 [22:40<05:44, 57.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.12243003398180008\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.18024620413780212\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.2584759294986725\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.22001716494560242\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 25/30 [23:34<04:42, 56.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.13958898186683655\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.2355027198791504\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.07934591174125671\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.33986231684684753\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 26/30 [24:29<03:43, 55.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.06421727687120438\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.07117953896522522\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.11645005643367767\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.21379454433918\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 27/30 [25:22<02:45, 55.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.06792408227920532\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.1246570572257042\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.1261330097913742\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.4066201448440552\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 28/30 [26:16<01:49, 54.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.03416148200631142\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.03891266882419586\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.1922222077846527\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.2704184949398041\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 29/30 [27:10<00:54, 54.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "Training loss (for one batch) at step 0: 0.04365459084510803\n",
      "Seen so far: 6 samples\n",
      "Training loss (for one batch) at step 200: 0.18410339951515198\n",
      "Seen so far: 1206 samples\n",
      "Training loss (for one batch) at step 400: 0.06513691693544388\n",
      "Seen so far: 2406 samples\n",
      "<MapDataset shapes: {image/encoded: (), image/label: (), image/roi: (4,)}, types: {image/encoded: tf.string, image/label: tf.int64, image/roi: tf.float32}>\n",
      "val___ loss (for one batch) at step 0: 0.11707638204097748\n",
      "Seen so far: 6 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [28:04<00:00, 56.14s/it]\n"
     ]
    }
   ],
   "source": [
    "train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9b262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
