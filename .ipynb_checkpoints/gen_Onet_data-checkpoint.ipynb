{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58198cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os,sys\n",
    " \n",
    "from detect import detect_pent,detect_Rnet\n",
    "\n",
    "RorO = 48 #24 Rnet,这里修改48可以生成 Onet数据集\n",
    " \n",
    "#这里修改48可以生成 Onet数据集\n",
    "stdsize = RorO\n",
    "\n",
    "pos_save_dir = \"data/\" + str(stdsize) + \"/positive\"\n",
    "part_save_dir = \"data/\" + str(stdsize) + \"/part\"\n",
    "neg_save_dir = \"data/\" + str(stdsize) + '/negative'\n",
    "#这里修改48可以生成 Onet数据集\n",
    "save_dir = \"data/\" + str(RorO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda282c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box, boxes):\n",
    "    \"\"\"Compute IoU between detect box and gt boxes\n",
    " \n",
    "    Parameters:\n",
    "    -----------\n",
    "    box: numpy array , shape (5, ): x1, y1, x2, y2, score\n",
    "        input box\n",
    "    boxes: numpy array, shape (n, 4): x1, y1, x2, y2\n",
    "        input ground truth boxes\n",
    " \n",
    "    Returns:\n",
    "    --------\n",
    "    ovr: numpy.array, shape (n, )\n",
    "        IoU\n",
    "    \"\"\"\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    box_area = (box[2] - box[0] + 1) * (box[3] - box[1] + 1)\n",
    "    area = (boxes[:, 2] - boxes[:, 0] + 1) * (boxes[:, 3] - boxes[:, 1] + 1)\n",
    " \n",
    "    # abtain the offset of the interception of union between crop_box and gt_box\n",
    "    xx1 = np.maximum(box[0], boxes[:, 0])\n",
    "    yy1 = np.maximum(box[1], boxes[:, 1])\n",
    "    xx2 = np.minimum(box[2], boxes[:, 2])\n",
    "    yy2 = np.minimum(box[3], boxes[:, 3])\n",
    " \n",
    "    # compute the width and height of the bounding box\n",
    "    w = np.maximum(0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0, yy2 - yy1 + 1)\n",
    " \n",
    "    inter = w * h\n",
    "    ovr = inter / (box_area + area - inter)\n",
    "    return ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b5c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkr(dr):\n",
    "    if not os.path.exists(dr):\n",
    "        os.mkdir(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797c494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation(base_dir, label_path):\n",
    "    '''读取文件的image，box'''\n",
    "    data = dict()\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    labelfile = open(label_path, 'r')\n",
    "    while True:\n",
    "        # 图像地址\n",
    "        imagepath = labelfile.readline().strip('\\n')\n",
    "        if not imagepath:\n",
    "            break\n",
    "        imagepath = base_dir + '/images/' + imagepath\n",
    "        images.append(imagepath)\n",
    "        # 人脸数目\n",
    "        nums = labelfile.readline().strip('\\n')\n",
    "     \n",
    "        one_image_bboxes = []\n",
    "        for i in range(int(nums)):\n",
    "           \n",
    "            bb_info = labelfile.readline().strip('\\n').split(' ')\n",
    "            #人脸框\n",
    "            face_box = [float(bb_info[i]) for i in range(4)]\n",
    "            \n",
    "            xmin = face_box[0]\n",
    "            ymin = face_box[1]\n",
    "            xmax = xmin + face_box[2]\n",
    "            ymax = ymin + face_box[3]\n",
    "            \n",
    "            one_image_bboxes.append([xmin, ymin, xmax, ymax])\n",
    "           \n",
    "        bboxes.append(one_image_bboxes)\n",
    "\n",
    "\n",
    "    data['images'] = images\n",
    "    data['bboxes'] = bboxes\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b259ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12880 pics in total\n"
     ]
    }
   ],
   "source": [
    "data = read_annotation('data/WIDER_train/','data/wider_face_train_bbx_gt.txt')\n",
    "annotations = data['bboxes']\n",
    "imgs = data['images']\n",
    "#annotations= np.load(\"labels8.npy\")#[:100,4].astype(np.float32)\n",
    "#imgs=np.load(\"imgs8.npy\")\n",
    " \n",
    "num = len(annotations)\n",
    "print(\"%d pics in total\" % num)\n",
    " \n",
    "#这里修改48可以生成 Onet数据集\n",
    "size_i = RorO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a9f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkr(save_dir)\n",
    "mkr(pos_save_dir)\n",
    "mkr(part_save_dir)\n",
    "mkr(neg_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1323430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_square(bbox):\n",
    "    \"\"\"Convert bbox to square\n",
    " \n",
    "    Parameters:\n",
    "    ----------\n",
    "    bbox: numpy array , shape n x 5\n",
    "        input bbox\n",
    " \n",
    "    Returns:\n",
    "    -------\n",
    "    square bbox\n",
    "    \"\"\"\n",
    "    square_bbox = bbox.copy()\n",
    " \n",
    "    h = bbox[:, 3] - bbox[:, 1] + 1\n",
    "    w = bbox[:, 2] - bbox[:, 0] + 1\n",
    "    max_side = np.maximum(h,w)\n",
    "    square_bbox[:, 0] = bbox[:, 0] + w*0.5 - max_side*0.5\n",
    "    square_bbox[:, 1] = bbox[:, 1] + h*0.5 - max_side*0.5\n",
    "    square_bbox[:, 2] = square_bbox[:, 0] + max_side - 1\n",
    "    square_bbox[:, 3] = square_bbox[:, 1] + max_side - 1\n",
    "    return square_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646f326d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[1,10,829,612] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/conv1/Conv2D (defined at /home/ecbm4040/4040_project/detect.py:207) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_331]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a198c6f5fafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mbbos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_bboxes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdetect_pent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mpen_bbos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpen_pre_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_pent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Pnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mbbos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_Rnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpen_pre_bboxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Rnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/4040_project/detect.py\u001b[0m in \u001b[0;36mdetect_pent\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mimg_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mcls_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mcls_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,10,829,612] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/conv1/Conv2D (defined at /home/ecbm4040/4040_project/detect.py:207) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_331]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "p_idx = 0 # positive\n",
    "n_idx = 0 # negative\n",
    "d_idx = 0 # dont care\n",
    "idx = 0\n",
    "box_idx = 0\n",
    "\n",
    "# 生成一系列txt文档用于存储Positive，Negative，Part三类数据的信息\n",
    "f1 = open(os.path.join(save_dir, 'pos_' + str(stdsize) + '.txt'), 'w')\n",
    "f2 = open(os.path.join(save_dir, 'neg_' + str(stdsize) + '.txt'), 'w')\n",
    "f3 = open(os.path.join(save_dir, 'part_' + str(stdsize) + '.txt'), 'w')\n",
    "\n",
    "#len(annotations) 只需要100张图片\n",
    "for i in range(100):\n",
    "    '''\n",
    "    print(annotations[i])\n",
    "    boxes = annotations[i][0:8].reshape(-1, 2)\n",
    "    ix=boxes[:,0].min()\n",
    "    iy=boxes[:,1].min()\n",
    "    ax=boxes[:,0].max()\n",
    "    ay=boxes[:,1].max()\n",
    "    boxes=np.array([[ix,iy,ax,ay]])\n",
    "    '''\n",
    "    \n",
    "    #my code\n",
    "    boxes = np.array(annotations[i])\n",
    "    \n",
    "    #image = imgs[i].copy()\n",
    "    \n",
    "    #my code\n",
    "    image = cv2.imread(imgs[i]).copy()\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    if size_i == 24:\n",
    "        bbos, pre_bboxes= detect_pent(image)\n",
    "    else:\n",
    "        pen_bbos, pen_pre_bboxes = detect_pent(image) #Pnet\n",
    "        bbos, pre_bboxes = detect_Rnet(image,pen_pre_bboxes) #Rnet\n",
    " \n",
    "    print(\"盒子数\",len(pre_bboxes))\n",
    " \n",
    "    if len(pre_bboxes) == 0:\n",
    "        continue\n",
    " \n",
    " \n",
    "    pre_bboxes = np.array(pre_bboxes)\n",
    "    dets = convert_to_square(pre_bboxes)\n",
    " \n",
    "    dets[:, 0:4] = np.round(dets[:, 0:4])\n",
    " \n",
    "    \n",
    "    #img = imgs[i]\n",
    "    \n",
    "    #my code\n",
    "    img = cv2.imread(imgs[i])\n",
    "\n",
    "    \n",
    "    idx += 1\n",
    " \n",
    "    height,width,channel = img.shape\n",
    " \n",
    "    neg_num = 0\n",
    "    for box in dets:\n",
    " \n",
    "        x_left,y_top,x_right,y_bottom = box[0:4].astype(int)\n",
    "        width = x_right - x_left + 1\n",
    "        height = y_bottom - y_top + 1\n",
    "        if width < 20 or x_left < 0 or y_top < 0 or x_right > img.shape[1] - 1 or y_bottom > img.shape[0] - 1:\n",
    "            continue\n",
    " \n",
    "        Iou = IoU(box,boxes)\n",
    " \n",
    "        cropped_im = img[y_top:y_bottom + 1, x_left:x_right + 1, :]\n",
    " \n",
    "        resized_im = cv2.resize(cropped_im, (stdsize, stdsize),\n",
    "                                interpolation=cv2.INTER_LINEAR)\n",
    " \n",
    "        # if np.max(Iou) < 0.2 and n_idx < 3.0 * p_idx + 1:\n",
    "        if np.max(Iou) < 0.3 and neg_num < 60:\n",
    "            save_file = os.path.join(neg_save_dir,\"%s.jpg\"%n_idx)\n",
    "            f2.write(str(stdsize)+\"/negative/%s\"% n_idx + \" 0\\n\")\n",
    "            cv2.imwrite(save_file,resized_im)\n",
    "            n_idx += 1\n",
    "            neg_num += 1\n",
    " \n",
    "        else:\n",
    "            idx_Iou = np.argmax(Iou)\n",
    "            assigned_gt = boxes[idx_Iou]\n",
    "            x1,y1,x2,y2 = assigned_gt\n",
    " \n",
    "            offset_x1 = (x1 - x_left) / float(width)\n",
    "            offset_y1 = (y1 - y_top) / float(height)\n",
    "            offset_x2 = (x2 - x_right) / float(width)\n",
    "            offset_y2 = (y2 - y_bottom) / float(height)\n",
    "            if np.max(Iou) >= 0.65:\n",
    "                save_file = os.path.join(pos_save_dir, \"%s.jpg\" % p_idx)\n",
    "                f1.write(str(stdsize)+\"/positive/%s\"%p_idx + ' 1 %.2f %.2f %.2f %.2f\\n' % (\n",
    "                    offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "                p_idx += 1\n",
    " \n",
    "            elif np.max(Iou) >= 0.4 and d_idx < 1.0 * p_idx + 1:\n",
    "                save_file = os.path.join(part_save_dir, \"%s.jpg\" % d_idx)\n",
    "                f3.write(str(stdsize)+\"/part/%s\"%d_idx + ' -1 %.2f %.2f %.2f %.2f\\n' % (\n",
    "                    offset_x1, offset_y1, offset_x2, offset_y2))\n",
    "                cv2.imwrite(save_file, resized_im)\n",
    "                d_idx += 1\n",
    " \n",
    "    print(\"%s images done, pos: %s part: %s neg: %s\" % (idx, p_idx, d_idx, n_idx))\n",
    " \n",
    " \n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "941ddae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"data/48\"\n",
    "size = 48\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "f1 = open(os.path.join(save_dir, 'pos_%s.txt'%(size)), 'r')\n",
    "f2 = open(os.path.join(save_dir, 'neg_%s.txt'%(size)), 'r')\n",
    "f3 = open(os.path.join(save_dir, 'part_%s.txt'%(size)), 'r')\n",
    " \n",
    "pos = f1.readlines()\n",
    "neg = f2.readlines()\n",
    "part = f3.readlines()\n",
    "f = open(os.path.join(save_dir, 'label-train%s.txt'%(size)), 'w')\n",
    " \n",
    "for i in range(int(len(pos))):\n",
    "    p = pos[i].find(\" \") + 1\n",
    "    pos[i] = pos[i][:p-1] + \".jpg \" + pos[i][p:-1] + \"\\n\"\n",
    "    f.write(pos[i])\n",
    "    \n",
    "for i in range(int(len(neg))):\n",
    "    p = neg[i].find(\" \") + 1\n",
    "    neg[i] = neg[i][:p-1] + \".jpg \" + neg[i][p:-1] + \" -1 -1 -1 -1\\n\"\n",
    "    f.write(neg[i])\n",
    "    \n",
    "for i in range(int(len(part))):\n",
    "    p = part[i].find(\" \") + 1\n",
    "    part[i] = part[i][:p-1] + \".jpg \" + part[i][p:-1] + \"\\n\"\n",
    "    f.write(part[i])\n",
    "\n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a43c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
